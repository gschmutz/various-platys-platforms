# `modern-data-platform` - Configuration v1.17.0

This is the documentation of the configuration settings which can be overwritten using a custom YAML file. All the defaults are defined in [`../modern-data-platform-stack/generator-config/vars/config.yml`](../modern-data-platform-stack/generator-config/vars/config.yml).

## Overall Settings

There are some overall settings which will control the behaviour for all or a group of services. These are listed in the table below.

| Config                                         	| Default 	| Since 	| Description                                                                                                                                                                        	                    	|
|------------------------------------------------	|:-------:	|-------	|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| `use_timezone`                             	|  	| 1.5.0 | The timezone to use for the whole stack. By default is empty so the timezone of the docker engine is not changed and it will run as `Etc/UTC`. If you want to set it to another timezone, then specify a Unix timezone string, such as `Europe/Zurich` or `America/New_York`. An overview on the valid timezones can be found here: <https://en.wikipedia.org/wiki/List_of_tz_database_time_zones> |  
| `private_docker_repository_name`                             	| `trivadis` 	| 1.5.0 | Docker images not available on public Docker Hub will be retrieved using this private repository. By default it points to `trivadis` and you have to login first, before you can use the generated stack, if you have selected a private image. Use this config to point to your own private docker registry if needed. |  
| `uid`                             	| `1000` 	| 1.9.0 | The UID to use when using the "user" property in a service to override the user inside the container. |  
| `env`           | ${PLATYS_ENV} 	| 1.16.0 | Optional environment identifier of this platys instance, by default take it from the environment variable (can be specified in the `.env` file), but can be changed to hardcoded value. Allowed values (taken from [DataHub](https://datahubproject.io/docs/graphql/enums/#fabrictype)): `dev`, `test`, `qa`, `uat`, `ei`, `pre`, `non_prod`, `prod`, `corp` |  
| `data_centers`                             	| `dc1,dc2` 	| 1.14.0 | A comma-separated list of data-center names, to use if the property `data_center_to_use` has a value != 0. |  
| `data_center_to_use`                             	| `0` 	| 1.14.0 | The data-center to use, if multiple DC should be simulated for a Kafka setup. |  
| `copy_cookbook_data_folder`                             	| `true` 	| 1.14.0 | Copy all the `data` folders of the various cookbook recipes into the `data-transfer/cookbook-data` folder. |  

## External Services

There are some overall settings which will control the behaviour for all or a group of services. These are listed in the table below.

| Config                                         	| Default 	| Since 	| Description                                                                                                                                                                        	                    	|
|------------------------------------------------	|:-------:	|-------	|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| `KAFKA_enable`                             	| `false` | 1.9.0 | Use external Kafka service, such as Confluent Cloud. Specify the cluster through the `KAFKA_bootstrap_servers` property.  |  
| `KAFKA_bootstrap_servers`                             	| `` 	| 1.9.0 | A comma-separated list of host and port pairs that addresses the external Kafka brokers |  
| `KAFKA_username`                             	| `` 	| 1.9.0 | Username to authenticate against the external Kafka cluster |  
| `KAFKA_password`                             	| `` 	| 1.9.0 | Password to authenticate against the external Kafka cluster |  
| `SCHEMA_REGISTRY_enable`                             	| `false` 	| 1.9.0 |  Use an external schema registry |  
| `SCHEMA_REGISTRY_url`                             	| `` 	| 1.9.0 | The URL of the external schema registry |  
| `S3_enable`                             	| `false` | 1.9.0 | Use external S3 service, such as AWS S3 cloud service or an on-premises S3 appliance. You have to configure two environment variables, `PLATYS_AWS_ACCESS_KEY` with the access key and `PLATYS_AWS_SECRET_ACCESS_KEY` with the access secret. This can be done on the on the docker host or in the `.env` file in the platform home (same folder where the `docker-compose.yml` is located). |  
| `S3_endpoint`                             	| `` | 1.9.0 | The endpoint address of the S3 external service |  
| `S3_path_style_access`                             	| `false` | 1.9.0 | Use Path Style Access if set to `true`, otherwise the default of virtual hosted-style access is used. |
| `ADLS_enable`                             	| `false` | 1.15.0 | Use external Azure Data Lake Storage Gen2 service. You have to configure two environment variables, `PLATYS_AZURE_ADLS_ACCESS_KEY` with the access key. This can be done on the on the docker host or in the `.env` file in the platform home (same folder where the `docker-compose.yml` is located). |  
| `ADLS_storage_account`                             	| `` | 1.15.0 | The name of the storage account for the ADLS service. |  
| `DATAHUB_enable`                             	| `false` | 1.16.0 | Use external DataHub service. Specify the DataHub GMS service through the `DATAHUB_gms_url` property.  |  
| `DATAHUB_gms_url`                             	| `` 	| 1.16.0 | the web url of the external DataHub GMS service instance to connect to. |  

## Platform Services

The configuration settings for enabling/disabling a given service are named `XXXXX_enable` where XXXXX is the name of the service (he used to be named `XXXXX_enabled` in version 1.0.0).
For each service there might be some other settings, such as controlling the number of nodes to start the service with, whether the service should map a data volume into the container or controlling some other proprietary configuration properties of the service itself.

### Stream Processing Ecosystem

| Config                                         	| Default 	| Since 	| Description                                                                                                                                                                        	                    	|
|------------------------------------------------	|:-------:	|-------	|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| [**_Apache Zookeeper_**](./services/zookeeper)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                	|         	|       	|                                                                                                                                                                                     	|
| `ZOOKEEPER_enable`                             	| `false` 	| 1.0.0 	| [Apache Zookeeper](https://zookeeper.apache.org/) is a coordination service used by Apache Kafka and Apache Atlas services. It is automatically enabled if using either of the two. 	|             	|                                
| `ZOOKEEPER_nodes`                              	|   `1`   	| 1.0.0 	| number of Zookeeper nodes                                                                                                                                                           	|
| `ZOOKEEPER_navigator_enable`                   	| `false` 	| 1.1.0 	| Zookeeper Navigator is a UI for managing and viewing zookeeper cluster.                                                                                                             	|      
| [**_Apache Kafka_**](./services/kafka)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                    	|         	|       	|                                                                                                                                                                                     	|
| `KAFKA_enable`                                 	| `false` 	| 1.0.0 	| Use confluent Kafka                                                                                                                                                                 	|             	|                                	|
| `KAFKA_edition`                      	| `community` 	| 1.2.0 	| The Kafka edition to use, one of `community` or `enterprise`                                                                                                                                               	|             	|                                	|
| `KAFKA_volume_map_data`                        	| `false` 	| 1.0.0 	| Volume map data folder into the Kafka broker                                                                                                                                        	|             	|                                	|
| `KAFKA_use_standard_port_for_external_interface`                        	| `true` 	| 1.14.0 	| Should the standard Port 9092 - 9095 to be used for the external interface or for the private interface (docker host)?                                                                                                                                      	|             	|                                	|
| `KAFKA_nodes`                                  	|   `3`   	| 1.0.0 	| number of Kafka Broker nodes to use                                                                                                                                                 	|             	|                                	|
| `KAFKA_use_kraft_mode`                                  	|   `false`   	| 1.13.0 	| use Zookeeper-Less setup of Kafka 2.8.0 (Confluent 6.2) available as a preview.                                                                                                                                                 	|             	|                                	|
| `KAFKA_internal_replication_factor`                    	| `3` 	| 1.6.0 	| the replication factor to use for the Kafka internal topics                                                                                                                                                      	|             	|                                	|
| `KAFKA_delete_topic_enable`                    	| `true` 	| 1.0.0 	| allow deletion of Kafka topics                                                                                                                                                      	|             	|                                	|
| `KAFKA_auto_create_topics_enable`              	| `false` 	| 1.0.0 	| allow automatic creation of Kafka topics                                                                                                                                            	|             	|                                	|
| `KAFKA_message_timestamp_type`              	| `CreateTime` 	| 1.8.0 	| Define whether the timestamp in the message is message create time or log append time. The value should be either `CreateTime` or `LogAppendTime`.                                                                                                                                            	|             	|                                	|
| `KAFKA_jmx_monitoring_prometheus_enable`              	| `false` 	| 1.12.0 	| Enable Kafka JMX Monitoring over Prometheus. If enabled, then `prometheus` and `grafana` are automatically enabled as well.                                                                                                                                            	|             	|                                	|
| `KAFKA_log_segment_bytes`              	| `1073741824` (1 GB) | 1.8.0 	| The maximum size of a single log file.                                                                                                                                            	|             	
| `KAFKA_log_retention_ms`              	| `` | 1.8.0 	| The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in `log.retention.hours` is used. If set to `-1`, no time limit is applied.                                                                                                                                            	|
| `KAFKA_log_retention_hours`              	| `168` (1 GB) | 1.8.0 	| The number of hours to keep a log file before deleting it (in hours), tertiary to `log.retention.ms` property                                                                                                                                            	|
| `KAFKA_log_retention_bytes`              	| `-1` (not used) | 1.8.0 	| The maximum size of the log before deleting it.                                                                                                                                            	|
| `KAFKA_compression_type`              	| `producer` | 1.8.0 	| Specify the final compression type for a given topic. This configuration accepts the standard compression codecs (`gzip`, `snappy`, `lz4`, `zstd`). It additionally accepts `uncompressed` which is equivalent to no compression; and `producer` which means retain the original compression codec set by the producer.                                                                                                                                            	|
| `KAFKA_min_insync_replicas`              	| `1`  | 1.8.0 	| When a producer sets acks to "all" (or "-1"), `min.insync.replicas` specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful. If this minimum cannot be met, then the producer will raise an exception (either NotEnoughReplicas or NotEnoughReplicasAfterAppend).                                                                                                                                  	|             	
| `KAFKA_replica_selector_class`              	|  	| 1.8.0 	| The fully qualified class name that implements ReplicaSelector. This is used by the broker to find the preferred read replica. By default, an implementation that returns the leader.                                                                                                                                            	|             	|                                	|
| `KAFKA_confluent_log_placement_constraints`              	| `{}` 	| 1.8.0 	| This configuration is a JSON object that controls the set of brokers (replicas) which will always be allowed to join the ISR. And the set of brokers (observers) which are not allowed to join the ISR. Only enabled if `KAFKA_edition` is set to `enterprise`. Find more information here: <https://docs.confluent.io/current/installation/configuration/broker-configs.html>.                                                                                                                                             	|             	|                                	|
| `KAFKA_confluent_tier_feature`              	| `false` 	| 1.8.0 	| enables Tiered Storage for a broker. Setting this to `true` allows a broker to utilize Tiered Storage                                                                                                                                             	|  
| `KAFKA_confluent_tier_enable`              	| `false` 	| 1.8.0 	| sets the default value for created topics. Setting this to `true` causes all non-compacted topics to be tiered                                                                                                                                             	|  
| `KAFKA_confluent_tier_backend`              	| `S3` 	| 1.8.0 	| refers to the cloud storage service to which a broker will connect, either `S3` for Amazon S3 or `GCS` for Google Cloud Storage.                                                                                                                                             	|  
| `KAFKA_confluent_tier_s3_bucket`              	| `kafka-logs` 	| 1.8.0 	| the S3 bucket name used for writing and reading tiered data                                                                                                                                             	|  
| `KAFKA_confluent_tier_s3_prefix`              	| `` 	| 1.8.0 	| This prefix will be added to tiered storage objects stored in S3.                                                                                                                                                  	|  
| `KAFKA_confluent_tier_s3_region`              	| `us-east-1` 	| 1.8.0 	| the S3 region used for writing and reading tiered data                                                                                                                                                  	|
| `KAFKA_confluent_tier_s3_aws_endpoint_override`              	| `` 	| 1.8.0 	| override the endpoint of the S3 storage, if an on-premises storage such as Minio is used.                                                                                                                                                  	|
| `KAFKA_confluent_tier_s3_force_path_style_access`              	| `false` 	| 1.13.0 	| Configures the client to use path-style access for all requests. This flag is not enabled by default. The default behavior is to detect which access style to use based on the configured endpoint and the bucket being accessed. Setting this flag will result in path-style access being forced for all requests.                                                                                                                                                  	|
| `KAFKA_confluent_tier_local_hotset_bytes`              	| `-1` 	| 1.8.0 	| When tiering is enabled, this configuration controls the maximum size a partition (which consists of log segments) can grow to on broker-local storage before we will discard old log segments to free up space. Log segments retained on broker-local storage is referred as the "hotset". Segments discarded from local store could continue to exist in tiered storage and remain available for fetches depending on retention configurations. By default there is no size limit only a time limit. Since this limit is enforced at the partition level, multiply it by the number of partitions to compute the topic hotset in bytes.                                                                                                                                                  	|
| `KAFKA_confluent_tier_local_hotset_ms`              	| `86400000` (1 day)	| 1.8.0 	| When tiering is enabled, this configuration controls the maximum time we will retain a log segment on broker-local storage before we will discard it to free up space. Segments discarded from local store could continue to exist in tiered storage and remain available for fetches depending on retention configurations. If set to -1, no time limit is applied.                                                                                                                                                	|
| `KAFKA_confluent_tier_archiver_num_threads`              	| `2` 	| 1.8.0 	| The size of the thread pool used for tiering data to remote storage. This thread pool is also used to garbage collect data in tiered storage that has been deleted.                                                                                                                                                  	|
| `KAFKA_confluent_tier_fetcher_num_threads`              	| `4` 	| 1.8.0 	| The size of the thread pool used by the TierFetcher. Roughly corresponds to number of concurrent fetch requests that can be served from tiered storage.                                                                                                                                                  	|
| `KAFKA_confluent_tier_topic_delete_check_interval_ms`              	| `10800000` (3 hours) 	| 1.8.0 	| Frequency at which tiered objects cleanup is run for deleted topics.                                                                                                                                                 	|
| `KAFKA_confluent_tier_metadata_replication_factor`              	| `1` 	| 1.8.0 	| The replication factor for the tier metadata topic (set higher to ensure availability).                                                                                                                                                  	|
| `KAFKA_log4j_root_level`              	| `INFO` 	| 1.14.0 	| Change the default log4j logging levels of Kafka broker.                                                                                                                                                  	|
| `KAFKA_log4j_loggers` | `` 	| 1.14.0 	| Add new logging levels for a Confluent Platform component, i.e. to override the log levels for Kafka controller and request loggers use `kafka.controller=TRACE,kafka.request.logger=WARN`.                                                                                                                                             	|
| `KAFKA_tools_log4j_level`              	| `INFO` 	| 1.14.0 	| Change the default log4j logging levels of the Kafka tools.                                                                                                                                                  	|
| [**_Kafka CLI_**](./services/kafka-cli)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                    	|             	|                               
| `KAFKA_CLI_enable`                                 	| `false` 	| 1.16.0 	| Use confluent Kafka                                                                                                                                                                 	|             	|                                	|
| **_Schema Registry_**   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                    	|             	|                                	|
| `SCHEMA_REGISTRY_enable`                 	| `false` 	| 1.14.0 	| Generate Confluent Schema Registry service                                                                                                                                          	|             	|                                	|
| `SCHEMA_REGISTRY_flavour`                  	| `confluent` 	| 1.14.0 	| Which schema registry to use, either `confluent` or `apicurio`                                                                                                                                           	|             	|                                	|
| `SCHEMA_REGISTRY_nodes`                  	| `false` 	| 1.14.0 	| number of Confluent Schema Registry nodes                                                                                                                                           	|             	|                                	|
| - [**_Confluent Schema Registry_**](./services/schema-registry)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                    	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_enable`                 	| `false` 	| 1.14.0 	| Generate Confluent Schema Registry service - **Deprecated!!** will just set the `SCHEMA_REGISTRY_enable` and the `SCHEMA_REGISTRY_flavour` to `confluent`.                                                                                                                                         	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_use_zookeeper_election` 	| `false` 	| 1.14.0 	| use Zookeeper for election of "master" Schema Registry node                                                                                                                         	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_replication_factor`     	|   `1`   	| 1.14.0 	| replication factor to use for the `_schemas` topic                                                                                                                                  	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_leader_eligibility`     	|   `true`   	| 1.14.0 	| if `true`, this node can participate in primary election. In a multi-colocated setup, turn this off for clusters in the secondary data center.                                                                                                                                  	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_mode_mutability`     	|   `true`   	| 1.14.0 	| if `true` the mode of this Schema Registry node can be changed.                                                                                                                                  	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_schema_compatibility_level`     	|   `backward`   	| 1.14.0 	| The schema compatibility type. One of `none`, `backward`, `backward_transitive`, `forward`, `forward_transitive`, `full` or `full_transitive`.                                                                                                                               	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_log4j_root_loglevel`     	|   `info`   	| 1.14.0 	| Change the `rootLogger` loglevel of the Schema Registry.                                                                                                                              	|             	|                                	|
| `CONFLUENT_SCHEMA_REGISTRY_debug`     	|   `false`   	| 1.14.0 	| Boolean indicating whether extra debugging information is generated in some error response entities.                                                                                                                               	|             	|                                	|
| - [**_Apicurio Registry_**](./services/apicurio-registry)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `APICURIO_SCHEMA_REGISTRY_storage`                  	| `kafkasql` 	| 1.14.0 	| The storage type to use, either `mem` for In-Memory, `sql` for Postgresql, 'mssql' for SQL Server or `kafkasql` for Kafka based storage.                                                                                                                                      	|             	|                                	|
| `APICURIO_SCHEMA_REGISTRY_sql_storage_database`                  	| `apicuriodb` 	| 1.14.0 	| The database to use if storage is `sql` or `mssql`.                                                                                                                                      	|             	|                                	|
| `APICURIO_SCHEMA_REGISTRY_sql_storage_user`                  	| `apicurio` 	| 1.14.0 	| The user to use if storage is `sql` or `mssql`.                                                                                                                                   	|             	|                                	|
| `APICURIO_SCHEMA_REGISTRY_sql_storage_password`                  	| `abc123!` 	| 1.14.0 	| The password to use if storage is `sql` or `mssql`.                                                                                                                                     	|             	|                                	|
| `APICURIO_auth_enabled`                  	| `false` 	| 1.14.0 	| Enable authentication using Keycloak? If set to `true` then `KEYCLOAK_enable` will be enabled automatically.                                                                                                                                     	|             	|                                	|
| `APICURIO_auth_anonymous_read_access_enabled`                  	| `false` 	| 1.14.0 	| Allow anonymous users (REST API calls with no authentication credentials provided) to make read-only calls to the REST API.                                                                                                                                     	|             	|                                	|
| `APICURIO_auth_import_default_users`                  	| `false` 	| 1.14.0 	| If set to `true`, imports the following pre-defined users `sr-view`, `sr-dev` and `sr-admin` into the `registry` realm.                                                                                                                                      	|             	|                                	|
| `APICURIO_basic_auth_enabled`                  	| `false` 	| 1.14.0 	| Enable basic authentication? To set it to `true`, `APICURIO_auth_enable` has to be enabled as well and Keycloak configured accordingly. Basic authentication is just the authentication API layer, the authentication will still happen over keycloak.                                                                                                                                    	|             	|                                	|
| `APICURIO_eventsourcing_enabled`                  	| `false` 	| 1.14.0 	| Enable Event Sourcing, i.e. enable the Schema Registry to send events when changes are made to the registry.                                                                                                                                     	|             	|                                	|
| `APICURIO_eventsourcing_transport`                  	| `kafka` 	| 1.14.0 	| The Protocol to use for transporting the events. Either `kafka` or `http` are supported. The events are formatted using the CNCF Cloud Events specification.                                                                                                                                    	|             	|                                	|
| `APICURIO_eventsourcing_kafka_topic`                  	| `registry-events` 	| 1.14.0 	| The Kafka topic to use, if `APICURIO_eventsourcing_transport` is set to `kafka`.                                                                                                                                    	|             	|                                	|
| `APICURIO_eventsourcing_http_endpoint`                  	| `registry-events` 	| 1.14.0 	| The HTTP endpoint to push the data to, if `APICURIO_eventsourcing_transport` is set to `http`.                                                                                                                                    	|             	|                                	|
| [**_Apache Kafka Connect_**](./services/kafka-connect)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                     	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_CONNECT_enable`                         	| `false` 	| 1.2.0 	| Generate Kafka Connect service                                                                                                                                                      	|             	|                                	|
| `KAFKA_CONNECT_nodes`                          	|   `1`   	| 1.13.0 	| number of Kafka Connect nodes                                                                                                                                                       	|             	|                                	|
| `KAFKA_CONNECT_connectors`                          	|      	| 1.6.0 	| A comma separated list of components to be installed from [Confluent Hub](https://www.confluent.io/hub). Specify identifier of the form owner/component:version for the component in Confluent Hub.                                                                                                                                                 	|  
| `KAFKA_CONNECT_config_providers`                          	|      	| 1.9.0 	|  A comma-separated list of names for [ConfigProviders](https://docs.confluent.io/home/connect/userguide.html#configprovider-interface). Allows to use variables in connector configurations that are dynamically resolved when the connector is (re)started. Can be used for secrets or any other configuration information which should be resolved dynamically at runtime.                                                                                                                                              	|   
| `KAFKA_CONNECT_config_providers_classes`                          	|      	| 1.9.0 	|  The Java class names for the providers listed in the `KAFKA_CONNECT_config_providers` property.                                                                                                                                              	|   
| `KAFKA_CONNECT_map_settings_file`                          	|  `false`    	| 1.9.0 	|  Map the `settings.properties` file placed in the `$DATAPLATFORM_HOME/conf.override/kafka-connect/` folder into the container. Use it when enabling the `FileConfigProvider` trough the `KAFKA_CONNECT_config_providers` and `KAFKA_CONNECT_config_providers_classes` properties.                                                                                                                                              	|                 	
| [**_ksqlDB_**](./services/ksqldb)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                  	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_KSQLDB_enable`                          	| `false` 	| 1.2.0 	| ksqlDB is streaming SQL on Kafka. If you enable it, then SCHEMA_REGISTRY_enable will be automatically set to `true`.                                                                                                                                                             	|             	|                                	|
| `KAFKA_KSQLDB_edition`                          	| `oss` 	| 1.15.0 	| the edition to use, either `oss` for the Open Source or `cp` for the Confluent Platform.                                                                                                                                                             	|             	|                                	|
| `KAFKA_KSQLDB_nodes`                           	|   `2`   	| 1.2.0 	| number of ksqlDB nodes                                                                                                                                                              	|             	|                                	|
| `KAFKA_KSQLDB_suppress_enabled`                           	|   `false`   	| 1.9.0 	| Enable the Suppress functionality which have been added with ksqldb 0.13.0                                                                                                                                                            	|     
| `KAFKA_KSQLDB_suppress_buffer_size_bytes`                           	|   ``   	| 1.9.0 	| Bound the number of bytes that the buffer can use for suppression. Negative size means the buffer will be unbounded. If the maximum capacity is exceeded, the query will be terminated.                                                                                                                                                            	|           	
| `KAFKA_KSQLDB_query_pull_table_scan_enabled`                           	|   `false`   	| 1.12.0 	| Config to control whether table scans are permitted when executing pull queries. Works with ksqlDB > 0.17.0.                                                                                                                                                            	|  
| `KAFKA_KSQLDB_response_http_headers_config`                           	|   ``   	| 1.12.0 	| Use to select which HTTP headers are returned in the HTTP response for Confluent Platform components. Specify multiple values in a comma-separated string using the format `[action][header name]:[header value]` where `[action]` is one of the following: `set`, `add`, `setDate`, or `addDate`.                                                                                                                                                           	|           	
| `KAFKA_KSQLDB_queries_file`                           	|   ``   	| 1.9.0 	| A file that specifies a predefined set of queries for the ksqlDB cluster.                                                                                                                                                            	|     
| `KAFKA_KSQLDB_use_embedded_connect`                           	|   `false`   	| 1.13.0 	| Enable embedded kafka connect. Place connector jars into `./plugins/kafka-connect` or install them from [Confluent Hub](https://www.confluent.io/hub) using the `KAFKA_KSQLDB_connect_connectors` property. **Important:** Will only be effective, if `KAFKA_CONNECT_enable` is set to `false`.                                                                                                                                                           	|
| `KAFKA_KSQLDB_connect_connectors`                           	|   ``   	| 1.13.0 	| A comma separated list of components to be installed from [Confluent Hub](https://www.confluent.io/hub). Specify identifier of the form owner/component:version for the component in Confluent Hub.                                                                                                                                                        	|      
| `KAFKA_KSQLDB_persistence_default_format_key`                           	|   `KAFKA`   	| 1.15.0 	| Sets the default value for the KEY_FORMAT property if one is not supplied explicitly in CREATE TABLE or CREATE STREAM statements.                                                                                                                                                        	|      
| `KAFKA_KSQLDB_persistence_default_format_value`                           	|   ``   	| 1.15.0 	| Sets the default value for the VALUE_FORMAT property if one is not supplied explicitly in CREATE TABLE or CREATE STREAM statements.                                                                                                                                                       	|      
| `KAFKA_KSQLDB_log_topic`                           	|   `ksql_processing_log`   	| 1.16.0 	| the name of the processing log Kafka topic.                                                                                                                                                       	|      
| [**_Materialize_**](./services/materialize)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                  	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `MATERIALIZE_enable`                          	| `false` 	| 1.12.0 	| Enable Materialize streaming database for real-time applications.                                                                                                                                                              	|             	|                                	|
| [**_Azkarra Streams_**](./services/azkarra-worker)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                  	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `AZKARRA_enable`                          	| `false` 	| 1.8.0 	| Enable Azkarra Streams Worker, a lightweight Java framework which makes easy to develop and operate Kafka Streams applications.                                                                                                                                                              	|             	|                                	|
| [**_Confluent Replicator_**](./services/confluent-replicator)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                  	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_REPLICATOR_enable`                          	| `false` 	| 1.6.0 	| Enable Confluent Replicator (part of Confluent Enterprise Platform).                                                                                                                                                             	|             	|                                	|
| [**_Kafka Mirror Maker 2_**](./services/mirror-maker2)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                  	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_MM2_enable`                          	| `false` 	| 1.14.0 	| Enable Kafka Mirror Maker 2.                                                                                                                                                             	|             	|                                	|
| [**_Confluent REST Proxy_**](./services/kafka-rest)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_RESTPROXY_enable`                       	| `false` 	| 1.2.0 	| Generate Confluent REST Proxy service                                                                                                                                               	|             	|                                	|
| [**_Confluent MQTT Proxy_**](./services/kafka-mqtt)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_MQTTPROXY_enable`                       	| `false` 	| 1.2.0 	| Generate Confluent MQTT Proxy service                                                                                                                                               	|             	|                                	|
| `KAFKA_MQTTPROXY_topic_regex_list`                       	| `` 	| 1.8.0 	| A comma-separated list of pairs of type <kafka topic>:<regex> that is used to map MQTT topics to Kafka topics.                                                                                                                                               	|             	|                                	|
| [**_Zilla_**](./services/zilla)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)            	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `ZILLA_enable`                       	| `false` 	| 1.15.0 	| Generate Zilla service                                                                                                                                               	|             	|                                	|
| [**_Lenses Box_**](./services/lenses-box)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `LENSES_BOX_enable`              	| `false` 	| 1.14.0 	| Generate Lenses Box (Development) service.                                                                                                                                     	|             	|                                	|
| `LENSES_BOX_license`              	| `false` 	| 1.14.0 	| Set the end-user-license string you have gotten from <http://lenses.io> by email.                                                                                                                                     	|             	|                                	|
| [**_kcat (used to be kafkacat)_**](./services/kcat)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KCAT_enable`              	| `false` 	| 1.13.0 	| Generate `kcat` CLI service                                                                                                                                         	|             	|                                	|
| [**_kaskade_**](./services/kaskade)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KASKADE_enable`              	| `false` 	| 1.16.0 	| Generate `kaskade` CLI service                                                                                                                                         	|             	|                                	|
| [**_kafkactl_**](./services/kafkactl)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKACTL_enable`              	| `false` 	| 1.15.0 	| Generate `kafkactl` CLI service                                                                                                                                         	|             	|                                
| [**_jikkou_**](./services/jikkou)  &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `JIKKOU_enable`              	| `false` 	| 1.14.0 	| Generate Jikkou service                                                                                                                                         	|             	|                                	|
| `JIKKOU_use_verbose_mode`              	| `false` 	| 1.14.0 	| Use `verbose` option when running the Jikkou tool.                                                                                                                                       	|             	|                                	|
| `JIKKOU_use_delete_topic_orphans_mode`              	| `false` 	| 1.14.0 	| Use `delete-topic-orphans` option to delete topics which exist on the cluster but absent from the specification files, when running the Jikkou tool.                                                                                                                                      	|             	|                                	|
| `JIKKOU_use_delete_config_orphans_mode`              	| `false` 	| 1.14.0 	| Use `delete-config-orphans` option to delete config entries overridden on the cluster but absent from the specification files, when running the Jikkou tool.                                                                                                                                      	|             	|                                	|
| `JIKKOU_exclude_internals_option`              	| `true` 	| 1.14.0 	| Use `exclude-internals` option to exclude internal topics, when running the Jikkou tool.                                                                                                                                     	|             	|                                	|
| `JIKKOU_exclude_resources_regexp`              	| `` 	| 1.14.0 	| Use `exclude` option specify a regex patterns to use for excluding resources, when running the Jikkou tool.                                                                                                                                     	|             	|                                	|
| `JIKKOU_include_resources_regexp`              	| `` 	| 1.14.0 	| Use `include` option specify a regex patterns to use for including resources, when running the Jikkou tool.                                                                                                                                     	|             	|                                	|
| `JIKKOU_set_labels`              	| `` 	| 1.14.0 	| A comma separted list of `key=value` pairs, one for each label to set.                                                                                                                                       	|             	|                                	|
| `JIKKOU_set_variables`              	| `` 	| 1.14.0 	| A comma separted list of `key=value` pairs, one for each variable to set.                                                                                                                                       	|             	|                                	|
| `JIKKOU_kafka_brokers_wait_for_enabled`              	| `true` 	| 1.16.0 	| Wait for kafka brokers to be available.                                                                                                                              	|             	|                                	|
| `JIKKOU_kafka_brokers_wait_for_retry_backoff_ms`              	| `1000` 	| 1.16.0 	|  The amount of time to wait before verifying that brokers are available.                                                                                                                              	|             	|                                	|
| `JIKKOU_kafka_brokers_wait_for_timeout_ms`              	| `120000` 	| 1.16.0 	|  Wait until brokers are available or this timeout is reached.                                                                                                                              	|             	|                                	|
| [**_Schema Registry UI_**](./services/schema-registry-ui)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `SCHEMA_REGISTRY_UI_enable`              	| `false` 	| 1.2.0 	| Generate Landoop Schema-Registry UI service                                                                                                                                         	|             	|                                	|
| `SCHEMA_REGISTRY_UI_use_public_ip`              	| `true` 	| 1.10.0 	| If `true` use PUBLIC_IP, if `false` use DOCKER_HOST_IP for the IP address of the schema registry API.                                                                                                                                          	|             	|                                	|
| `SCHEMA_REGISTRY_UI_map_resolv_conf`              	| `true` 	| 1.13.0 	| If `true` the `conf/resolv.conf` is mapped into the container to avoid the `panic: runtime error: slice bounds out of range` when running Docker on an actual Ubunutu.                                                                                                                                          	|             	|                                	|
| [**_Kafka Topics UI_**](./services/kafka-topics-ui)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_TOPICS_UI_enable`              	| `false` 	| 1.4.0 	| Generate Landoop Kafka Topics UI service                                                                                                                                         	|             	|                                	|
| `KAFKA_TOPICS_UI_map_resolv_conf`              	| `true` 	| 1.13.0 	| If `true` the `conf/resolv.conf` is mapped into the container to avoid the `panic: runtime error: slice bounds out of range` when running Docker on an actual Ubunutu.                                                                                                                                          	|             	|                                	|
| [**_Kafka Connect UI_**](./services/kafka-connect-ui)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_CONNECT_UI_enable`                      	| `false` 	| 1.2.0 	| Generate Landoop Connect UI service                                                                                                                                                 	|             	|                                	|
| `KAFKA_CONNECT_UI_map_resolv_conf`              	| `true` 	| 1.13.0 	| If `true` the `conf/resolv.conf` is mapped into the container to avoid the `panic: runtime error: slice bounds out of range` when running Docker on an actual Ubunutu.                                                                                                                                          	|             	|                                	|
| [**_Cluster Manger for Apache Kafka (CMAK)_**](./services/cmak)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `CMAK_enable`                         	| `false` 	| 1.3.0 	| Generate CMAK (Cluster Manger for Apache Kafka) service (used to be Kafka Manager)                                                                                                                                                      	|             	|                                	|
| `CMAK_auth_enabled`                         	| `false` 	| 1.7.0 	| if set to true then the manager will be secured with basic authentication                                                                                                                                              	|             	|                                	|
| `CMAK_username`                         	| `admin` 	| 1.7.0 	| the username to use for basic auth                                                                                                                                              	|             	|                                	|
| `CMAK_password`                         	| `abc123!` 	| 1.7.0 	| the password to use for basic auth                                                                                                                                              	|             	|                                	|
| [**_Kafdrop_**](./services/kafdrop)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFDROP_enable`                         	| `false` 	| 1.2.0 	| [Kafdrop](https://github.com/obsidiandynamics/kafdrop) is a Kafka UI service, which can be used to administer and managed a Kafka cluster.                                          	|             	|                                	|
| [**_Kafka Admin_**](./services/kadmin)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KADMIN_enable`                          	| `false` 	| 1.2.0 	| Generate KAdmin service                                                                                                                                                             	|             	|                                	|
| [**_Kafka GUI for Apache Kafka (AKHQ)_**](./services/akhq)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `AKHQ_enable`                         	| `false` 	| 1.3.0 	| Generate AKHQ (used to be KafkaHQ) service                                                                                                                                                            	|             	|                                	|
| `AKHQ_read_only_mode`                         	| `false` 	| 1.16.0 	| Setup AKHQ to read-only?                                                                                                                                                            	|             	|                                	|
| `AKHQ_topic_page_size`                         	| `25` 	| 1.16.0 	| number of topics per page.                                                                                                       	|             	|                                	|
| `AKHQ_topic_data_size`                         	| `50` 	| 1.16.0 	| max record per page when showing topic data.                                                                                                       	|             	|                                	|
| `AKHQ_topic_data_poll_timeout`                         	| `1000` 	| 1.16.0 	| The time, in milliseconds, spent waiting in poll if data is not available in the buffer.                                                                                                       	|             	|                                	|
| `AKHQ_topic_data_kafka_max_message_length`                         	| `1000000` 	| 1.16.0 	| Max message length allowed to send to UI when retrieving a list of records (in bytes)                                                                                                       	|             	|                                	|
| `AKHQ_default_view`                         	| `HIDE_INTERNAL` 	| 1.16.0 	| Configure the default topic list view, one of `ALL`, `HIDE_INTERNAL`, `HIDE_INTERNAL_STREAM`, `HIDE_STREAM`.                                                                                                       	|             	|                                	|
| `AKHQ_sort`                         	| `OLDEST` 	| 1.16.0 	| Configure the default sort order for topic data, one of `OLDEST`, `NEWEST`.                                                                                                       	|             	|                                	|
| `AKHQ_show_consumer_groups`                         	| `true` 	| 1.16.0 	| Should AKHQ display the consumer groups column on a topic?                                                                                            	|             	|                                	|
| `AKHQ_show_all_consumer_groups`                         	| `true` 	| 1.16.0 	| Should AKHQ expand the consumer group list instead of just showing one?                                                                                            	|             	|                                	|
| `AKHQ_show_last_record`                         	| `true` 	| 1.16.0 	| Should AKHQ display the last record timestamp sent to a topic?                                                 	|             	|                                	|
| [**_Kafka UI_**](./services/kafka-ui)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_UI_enable`                         	| `false` 	| 1.11.0 	| Generate Kafka UI service                                                                                                                                                            	|             	|                                	|
| [**_EFAK (previously Kafka Eagle)_**](./services/efak)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `EFAK_enable`                         	| `false` 	| 1.13.0 	| Generate EFAK (Kafak Eagle) service                                                                                                                                                            	|             	|                                	|
| [**_Kowl_**](./services/kowl)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KOWL_enable`                         	| `false` 	| 1.13.0 	| Generate Kowl service                                                                                                                                                            	|             	|                                	|
| [**_Redpanda Console_**](./services/redpanda-console)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `REDPANDA_CONSOLE_enable`                         	| `false` 	| 1.16.0 	| Generate Redpanda Console (new home for Kowl) service                                                                                                                                                            	|             	|                                	|
| `REDPANDA_CONSOLE_edition`                         	| `oss` 	| 1.16.0 	| The edition of Redpanda Console, either `oss` or `enterprise`.                                                                                      	|             	|                                	|
| [**_Kouncil_**](./services/kouncil)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KOUNCIL_enable`                         	| `false` 	| 1.14.0 	| Generate Kouncil service                                                                                                                                                            	|             	|                                	|
| [**_Kafka Magic_**](./services/kafka-magic)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_MAGIC_enable`                         	| `false` 	| 1.14.0 	| Generate Kafka Magic service                                                                                                                                                            	|             	|                                	|
| [**_Kafka WebView_**](./services/kafka-magic)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_WEBVIEW_enable`                         	| `false` 	| 1.15.0 	| Generate Kafka WebView service                                                                                                                                                            	|             	|                                	|
| [**_kpow_**](./services/kpow)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KPOW_enable`                         	| `false` 	| 1.16.0 	| Generate kpow service                                                                                                                                                            	|             	|                                	|
| `KPOW_edition`                         	| `cc` 	| 1.16.0 	| The edition to use, either `ce` (community edition) or `se` (standard edition) or `ee` (enterprise edition)                                                                                                                                                         	|             	|                                	|
| `KPOW_use_external_license_info`                         	| `false` 	| 1.16.0 	| if `true`, then the license information should be placed in a file called `./license/kpow/kpow-license.env`, otherwise the config settings `KPOW_licenseXXX` should be used.                                                                                                                                                         	|             	|                                	|
| `KPOW_license_id`                         	| `` 	| 1.16.0 	| The kpow license id you retrieved with your license. You can get a trial license from <https://kpow.io/get-started/#individual>.                                                                                                                                                         	|             	|                                	|
| `KPOW_license_code`                         	| `` 	| 1.16.0 	| The kpow license code you retrieved with your license.                                                                                                                                                          	|             	|                                	|
| `KPOW_licensee`                         	| `` 	| 1.16.0 	| The kpow license you retrieved with your license.                                                                                                                                                          	|             	|                                	|
| `KPOW_license_signature`                         	| `` 	| 1.16.0 	| The kpow license signature you retrieved with your license.                                                                                                                                                          	|             	|                                	|
| `KPOW_license_expiry`                         	| `` 	| 1.16.0 	| The kpow license expiry you retrieved with your license.                                                                                                                                                          	|             	|                                	|
| [**_Conduktor Platform_**](./services/conduktor-platform)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `CONDUKTOR_PLATFORM_enable`                         	| `false` 	| 1.16.0 	| Generate Conduktor Platform service                                                                                                                                                            	|             	|                                	|
| `CONDUKTOR_PLATFORM_license_key`                         	| `` 	| 1.16.0 	| the Conduktor license key for the Enterprise plan. Leave empty for the free plan.                                                                                                                                                             	|             	|                                	|
| `CONDUKTOR_PLATFORM_organisation_name`                         	| `default` 	| 1.16.0 	| The name of the organisation.                                                                                                                                                            	|             	|                                	|
| `CONDUKTOR_PLATFORM_admin_email`                         	| `admin@platys.io` 	| 1.16.0 	| Admin user name (either a username or an email address).                                                                                                                                                            	|             	|                                	|
| `CONDUKTOR_PLATFORM_admin_psw`                         	| `abc123!` 	| 1.16.0 	| Admin user password.                                                                                                                                                            	|             	|                                	|
| `CONDUKTOR_PLATFORM_use_external_postgres`                         	| `false` 	| 1.16.0 	| Use external Postgresql database for the Conduktor metadata.                                                                                                                                                            	|             	|                                	|
| `CONDUKTOR_PLATFORM_postgres_host`                       	| `postgresql` 	| 1.16.0 	| Hostname of the Postgresql database, applicable if `CONDUKTOR_PLATFORM_use_external_postgres` is set to `true`.                                                                                                                                          	|             	|                                	|
| `CONDUKTOR_PLATFORM_postgres_port`                         	| `5432` 	| 1.16.0 	| Port of the Postgresql database, applicable if `CONDUKTOR_PLATFORM_use_external_postgres` is set to `true`.                                                                                                                                                         	|             	|                                	|
| `CONDUKTOR_PLATFORMpostgres_db`                       	| `postgres` 	| 1.16.0 	| Database name of the Postgresql database, applicable if `CONDUKTOR_PLATFORM_use_external_postgres` is set to `true`.                                                                                                                                           	|             	|                                	|
| `CONDUKTOR_PLATFORM_postgres_username`                       	| `postgres` 	| 1.16.0 	| Username of the Postgresql database, applicable if `CONDUKTOR_PLATFORM_use_external_postgres` is set to `true`.                                                                                                                                           	|             	|                                	|
| `CONDUKTOR_PLATFORM_postgres_password`                       	| `abc123!` 	| 1.16.0 	| Password of the Postgresql database, applicable if `CONDUKTOR_PLATFORM_use_external_postgres` is set to `true`.                                                                                                                                           	|             	|                                	|
| [**_Kafkistry_**](./services/kafkistry)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKISTRY_enable`                         	| `false` 	| 1.16.0 	| Generate Kafkistry service                                                                                                                                                            	|             	|                                	|
| [**_Kafka Connector Board_**](./services/kafka-connector-board)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_CONNECTOR_BOARD_enable`                         	| `false` 	| 1.16.0 	| Generate Kafka Connector Board service                                                                                                                                                            	|             	|                                	|
| [**_Streams Explorer_**](./services/streams-explorer)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `STREAMS_EXPLORER_enable`                         	| `false` 	| 1.11.0 	| Generate Streams Explorer service                                                                                                                                                            	|             	|                                	|
| [**_Kafka Lag Exporter_**](./services/kafka-lag-exporter)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_LAG_EXPORTER_enable`                         	| `false` 	| 1.12.0 	| Generate Kafka Lag Exporter service                                                                                                                                                            	|             	|                                	|
| [**_Remora_**](./services/remora)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `REMORA_enable`                         	| `false` 	| 1.14.0 	| Generate Remora service                                                                                                                                                            	|             	|                                	|
| [**_Burrow_**](./services/burrow)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `BURROW_enable`                          	| `false` 	| 1.14.0 	| Generate Burrow service                                                                                                                                                             	|             	|                                	|
| `BURROW_UI_enable`                          	| `false` 	| 1.14.0 	| Generate Burrow UI service                                                                                                                                                             	|             	|                                	|
| `BURROW_DASHBOARD_enable`                          	| `false` 	| 1.14.0 	| Generate Burrow Dashboard service                                                                                                                                                             	|             	|                                	|
| [**_Confluent Control Center_**](./services/confluent-control-center)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `KAFKA_CCC_enable`                             	| `false` 	| 1.1.0 	| Generate Confluent Metrics Reporter service                                                                                                                                         	|             	| KAFKA_entreprise_enable = true 	|
| [**_Debezium Server_**](./services/debezium-server)     &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `DEBEZIUM_SERVER_enable`                      	| `false` 	| 1.13.0 	| Generate Debezium Server service                                                                                                                                                 	|             	|                                	|
| `DEBEZIUM_SERVER_volume_map_data`                            	| `false` 	| 1.13.0 	| Volume map data folder into the Debezium Server service                                                                                                                                                          	|             	|                                	|
| [**_Debezium UI_**](./services/debezium-ui)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `DEBEZIUM_UI_enable`                      	| `false` 	| 1.12.0 	| Generate Debezium UI service                                                                                                                                                 	|             	|                                	|

### Big Data Ecosystem

| Config                                         	| Default 	| Since 	| Description                                                                                                                                                                        	                    	|
|------------------------------------------------	|:-------:	|-------	|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| [**_Apache Hadoop_**](./services/hadoop)  &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                           	|         	|       	|                                                                                                                                                                                     	|
| `HADOOP_enable`                                	| `false` 	| 1.0.0 	| Generate Hadoop services                                                                                                                                                            	|             	|                                	|
| `HADOOP_datanodes`                             	|   `2	`   | 1.0.0 	| number of Hadoop Datanodes                                                                                                                                                      	    |             	|                                	|
| [**_Apache Spark_**](./services/spark)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                            	|         	|       	|                                                                                                                                                                                     	|
| `SPARK_enable`                                 	| `false` 	| 1.0.0 	| Generate Spark services                                                                                                                                                             	|             	|                                	|
| `SPARK_base_version`                                 	| `2.4` 	| 1.15.0 	| Which base version of Spark to use, one of `2.4` or `3.1` or `3.2`. Replaces `SPARK_major_version` from `1.15.0`.                                                                                                                                                         	|             	
| `SPARK_catalog`                                 	| `in-memory` 	| 1.2.0 	| the catalog to use for Spark, either use `in-memory` or `hive`.                                                                                                                                                             	|             	|                                	|
| `SPARK_workers`                                	|   `2`   	| 1.0.0 	| number of Spark Worker nodes                                                                                                                                                        	|             	|                                	|
| `SPARK_master_opts`                                	|      	| 1.10.0 	| Configuration properties that apply only to the master in the form "-Dx=y" (default: none). See [here](https://spark.apache.org/docs/latest/spark-standalone.html) list of possible options.                                                                                                                                                       	|             	
| `SPARK_worker_cores`                                	|      	| 1.10.0 	| Total number of cores to allow Spark applications to use on the machine (default: all available cores).                                                                                                                                                       	|
| `SPARK_worker_memory`                                	|      	| 1.10.0 	| Total amount of memory to allow Spark applications to use on the machine, e.g. 1000m, 2g (default: total memory minus 1 GiB); note that each application's individual memory is configured using its spark.executor.memory property.                                                                                                                                                       	|
| `SPARK_worker_opts`                                	|   `-Dspark.worker.cleanup.enabled=true`   	| 1.10.0 	| Configuration properties that apply only to the worker in the form "-Dx=y" (default: none). See [here](https://spark.apache.org/docs/latest/spark-standalone.html) list of possible options.                                                                                                                                                       	|             	
| `SPARK_jars_repositories`                                	|      	| 1.6.0 	| Comma-separated list of additional remote repositories to search for the maven coordinates given with `--packages` or `spark.jars.packages` (`spark.jars.repositories` runtime environment setting)                                                                                                                                                       	|             	|                                	|
| `SPARK_jars`                                	|      	| 1.8.0 	| Comma-separated list of jars to include on the driver and executor classpath. Globs are allowed.                                                                                                                                                      	|             	|                                	|
| `SPARK_jars_packages`                                	|      	| 1.5.2 	| Comma-separated list of Maven coordinates of jars to include on the driver and executor classpath (will be added to the `spark.jars.packages` runtime environment setting). The transitive dependencies are downloaded automatically.                                                                                                                                                       	|             	|                                	|
| `SPARK_install_jars_packages`                                	|      	| 1.16.0 	| Comma-separated list of Maven coordinates of jars to install into `/spark/jars` when starting Spark. The Maven dependencies are downloaded without transitive dependencies. You have to manually assure, that transitive dependencies are included.                                                                                                                                                       	|             	|                                	|
| `SPARK_jars_excludes`                                	|      	| 1.8.0 	| Comma-separated list of `groupId:artifactId`, to exclude while resolving the dependencies provided in `spark.jars.packages` to avoid dependency conflicts.                                                                                                                                                        	|             	|                                	|
| `SPARK_jars_ivySettings`                                	|      	| 1.5.2 	| Path to an Ivy settings file to customize resolution of jars specified using spark.jars.packages instead of the built-in defaults, such as maven central (`spark.jars.ivysettings` runtime environment setting)                                                                                                                                                       	|             	|                                	|
| `SPARK_driver_extraJavaOptions`                                	|      	| 1.5.2 	| A string of extra JVM options to pass to the driver `spark.driver.extraJavaOptions` runtime environment setting                                                                                                                                                      	|             	|                                	|
| `SPARK_executor_extraJavaOptions`                                	|      	| 1.5.2 	| A string of extra JVM options to pass to the executor `spark.executor.extraJavaOptions` runtime environment setting                                                                                                                                                       	|             	|                                	|
| `SPARK_sql_warehouse_dir`                                	|  ''    	| 1.16.0 	| A string specifying the default Spark SQL Hive Warehouse location (`spark.sql.warehouse.dir` runtime environment setting). If left empty, then if defaults to `hdfs://namenode:9000/user/hive/warehouse` if using HDFS, `s3a://admin-bucket/hive/warehouse` if using S3 and `file:///hive/warehouse` if none of the two.                                                                                                                                                   	|             	|                                	|
| `SPARK_cores_max`                              	|  	| 1.10.0 	| the maximum amount of CPU cores to request for the application from across the cluster (not from each machine). If not set, the default will be `spark.deploy.defaultCores` to be set through `SPARK_MASTER_OPTS`.                                                                                                                                                  	|  
| `SPARK_executor_memory`                              	|  	| 1.10.0 	| Amount of memory to use per executor process, in the same format as JVM memory strings with a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g). If not set, the default will be `1g`.                                                                                                                                                  	|  
| `SPARK_table_format_type`                              	|  ''	| 1.16.0 	| The table format to enable in Spark, either 'delta', 'iceberg' or 'hudi'                                                                                                                                                 	|  
| [**_Apache Spark History Server_**](./services/spark-history)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `SPARK_HISTORYSERVER_enable`                         	| `false` 	| 1.0.0 	| Generate Spark History Server                                                                                                                                                       	|             	|                                	|
| [**_Apache Spark Thrift Server_**](./services/spark-thriftserver)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `SPARK_THRIFTSERVER_enable`                          	| `false` 	| 1.0.0 	| Generate Spark Thrift Server                                                                                                                                                        	|             	|                                	|
| `SPARK_THRIFTSERVER_cores_max`                              	|  	| 1.16.0 	| the maximum amount of CPU cores to request for the application from across the cluster (not from each machine). If not set, the default will be `spark.deploy.defaultCores` to be set through `SPARK_MASTER_OPTS`.                                                                                                                                                  	|  
| `SPARK_THRIFTSERVER_executor_memory`                              	|  	| 1.16.0 	| Amount of memory to use per executor process, in the same format as JVM memory strings with a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g). If not set, the default will be `1g`.                                                                                                                                                  	|  
| [**_Apache Livy_**](./services/livy)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `LIVY_enable`                                  	| `false` 	| 1.1.0 	| Generate Spark Livy Server                                                                                                                                                          	|             	|                                	|
| [**_Apache Flink_**](./services/flink)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)  ![arm](./images/arm.png)                           	|         	|       	|                                                                                                                                                                                     	|
| `FLINK_enable`                                 	| `false` 	| 1.13.0 	| Generate Flink services                                                                                                                                                             	|             	|                                	|
| `FLINK_taskmanagers`                                	|   `1`   	| 1.13.0 	| number of Flink TaskManager nodes                                                                                                                                                        	|             	|                                	|
| `FLINK_SQL_CLI_enable`                                 	| `false` 	| 1.13.0 	| Generate Flink SQL CLI service                                                                                                                                                             	|             	|                                	|
| [**_Nussknacker_**](./services/nussknacker)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)  ![arm](./images/arm.png)                           	|         	|       	|                                                                                                                                                                                     	|
| `NUSSKNACKER_enable`                                 	| `false` 	| 1.16.0 	| Generate Nussknacker services                                                                                                                                                             	|             	|                                	|
| `NUSSKNACKER_scenario_type`                                 	| `streaming` 	| 1.16.0 	| The processing mode (how a scenario deployed on an engine interacts with the outside world), one of `streaming`, `streaming-lite-embedded`, `request-response-embedded`.                                                                                                                                                            	|             	|                                	|
| [**_Apache Tika_**](./services/tika)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|             	|                                	|
| `TIKA_enable`                                  	| `false` 	| 1.13.0 	| Generate Apache Tika Server                                                                                                                                                          	|             	|                                	|
| `TIKA_edition`                                  	| `minimal` 	| 1.13.0 	| either `minimal` which contains only Apache Tika and it's core dependencies or `full`, which also includes dependencies for the GDAL and Tesseract OCR parsers                                                                                                                                                        	|             	|                                	|
| [**_Apache Hive_**](./services/hive)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                                	|         	|       	|                                                                                                                                                                                     	|
| `HIVE_enable`                                  	| `false` 	| 1.0.0 	| Generate Hive service                                                                                                                                                               	|             	|                                	|
| [**_Apache Hue_**](./services/hue)   &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|    
| `HUE_enable`                                   	| `false` 	| 1.0.0 	| Generate Hue UI service                                                                                                                                                             	|             	|                                	|

### Governance & Security

| Config                                         	| Default 	| Since 	| Description                                                                                                                                                                        	                    	|
|------------------------------------------------	|:-------:	|-------	|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|
| [**_Apache Avro Tools_**](./services/avrotools-cli)     &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                  	|         	|       	|                                                                                                                                                                                     	|   
| `AVRO_TOOLS_enable`                                 	| `false` 	| 1.14.0 	| Generate Avro Tools CLI service.                                                                                                                                                              	|             	|                                	|
| [**_Apache Parquet Tools_**](./services/parquet-tools)     &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                  	|         	|       	|                                                                                                                                                                                     	|   
| `PARQUET_TOOLS_enable`                                 	| `false` 	| 1.16.0 	| Generate Parquet Tools CLI service.                                                                                                                                                              	|             	|                                	|
| [**_Apache Atlas_**](./services/atlas)     &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                  	|         	|       	|                                                                                                                                                                                     	|   
| `ATLAS_enable`                                 	| `false` 	| 1.0.0 	| Generate Atlas service                                                                                                                                                              	|             	|                                	|
| `ATLAS_provision_atlas_sample_data`                                 	| `false` 	| 1.2.0 	| Provision Apache Atlas sample data?                                                                                                                                                              	|             	|                                	|
| `ATLAS_provision_amundsen_sample_data`                                 	| `false` 	| 1.2.0 	| Provision Amundsen sample types?                                                                                                                                                          	|             	|                                	|
| `ATLAS_install_hive_hook`                                 	| `false` 	| 1.2.0 	| Install the Hive Hook into the `hive-server`? Only relevant if `HIVE_enable` is set to `true`.                                                                                                                                                         	|             	
| [**_DataHub_**](./services/datahub)    &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|      
| `DATAHUB_enable`                              	| `false` 	| 1.4.0 	| Generate DataHub service                                                                                                                                                           	|           
| `DATAHUB_volume_map_data`                              	| `false` 	| 1.4.0 	| should the data of the databases be mapped to the outside of the container.                                                                                                                                                           	|  
| `DATAHUB_mae_consumer_standalone`                              	| `false` 	| 1.13.0 	| enable standalone MAE consumer? If set to `false`, the MAE will be started as part of the GMS service.                                                                                                                                                          	|     
| `DATAHUB_mce_consumer_standalone`                              	| `false` 	| 1.13.0 	| enable standalone MCE consumer?  If set to `false`, the MAE will be started as part of the GMS service.                                                                                                                                                                             	|  
| `DATAHUB_ui_ingestion_enabled`                              	| `true` 	| 1.16.0 	| enable ingestion over DataHub UI.                                                                                                                                                                             	|  
| `DATAHUB_analytics_enabled`                              	| `false` 	| 1.16.0 	| enable DataHub client-side analytics.                                                                                                                                                                             	|  
| `DATAHUB_use_kibana`                              	| `false` 	| 1.14.0 	| enable Kibana service on the Eleasticsearch database of DataHub.                                                                                                                                                                           	|    
| `DATAHUB_auth_policies_enabled`                              	| `true` 	| 1.14.0 	| enable the Policies feature?                                                                                                                                                                          	|    
| `DATAHUB_telemetry_enabled`                              	| `false` 	| 1.16.0 	| enable sending of Telemetry to the DataHub project?                                                                                                                                                                          	|    
| `DATAHUB_precreate_topics`                              	| `true` 	| 1.16.0 	| pre-create Kafka Topics on startup?                                                                                                                                                                          	|    
| `DATAHUB_graph_service_impl`                              	| `neo4j` 	| 1.14.0 	| The Graph database to be used as the backend, either one of `neo4j` or `elasticsearch`.                                                                                                                                                                            	|   
| `DATAHUB_graph_service_diff_mode_enabled`                              	| `true` 	| 1.16.0 	| enable diff mode for graph writes?
.                                                                                                                                                                            	|   
| `DATAHUB_provision_sample_data`                              	| `false` 	| 1.14.0 	| Should sample data be provisioned?                                                                                                                                                                        	| 
| `DATAHUB_secret`                              	| `abc123!abc123!` 	| 1.16.0 	| Allows for changing the datahub secret.                                                                                                                                                                   	|  
| `DATAHUB_map_user_props`                              	| `false` 	| 1.16.0 	| Map the `user.props` file from `./secret/datahub` into the `datahub-frontend-react` container for changing the `datahub` user password or for adding new users.                                                                                                                                                                  	|      
| [**_Amundsen_**](./services/amundsen)    &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|      
| `AMUNDSEN_enable`                              	| `false` 	| 1.0.0 	| Generate Amundsen service                                                                                                                                                           	|           
| `AMUNDSEN_metastore`                              	| `amundsen` 	| 1.2.0 	| the Amundsen backend to use, either `amundsen` or `atlas`.                                                                                                                                                           	|
| [**_Marquez_**](./services/marquez)    &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                              	|         	|       	|                                                                                                                                                                                     	|      
| `MARQUEZ_enable`                              	| `false` 	| 1.5.0 	| Generate [Marquez](https://marquezproject.github.io/marquez/) service, an open source metadata service for the collection, aggregation, and visualization of a data ecosystems metadata.                                                                                                                                                           	|           
| `MARQUEZ_volume_map_data`                              	| `false` 	| 1.5.0 	| should the data of the databases be mapped to the outside of the container.                                                                                                                                                           	|           
| `MARQUEZ_provision_marquez_sample_data `                              	| `false` 	| 1.5.0 	| Provision Marquez sample data.                                                                                                                                                           	|
| [**_Apache Ranger_**](./services/ranger)     &nbsp;&nbsp;&nbsp;&nbsp;![x86-64](./images/x86-64.png)                  	|         	|       	|                                                                                                                                                                                     	|   
| `RANGER_enable`                                 	| `false` 	| 1.5.0 	| Generate [Apache Ranger](https://ranger.apache.org/) service. Ranger is a framework to enable, monitor and manage comprehensive data security across the Hadoop platform.                                                                                                                                                              	|             	|                                	|
| `RANGER_postgresql_volume_map_data`                                 	| `false` 	| 1.8.0 	| Volume map the data to the outside into the container_volume folder.                                                                                                                                                              	|             	|                                	|